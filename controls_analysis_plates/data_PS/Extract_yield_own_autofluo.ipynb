{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim here is to start the proper extraction process as was dicussed with Olivier:\n",
    "- CV 30 as a limit for outliers\n",
    "- verification of duplicates between plates\n",
    "- mean of zero and reference for yield calculations, and not all combinations\n",
    "- once it's proven to work the other scripts will go to archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The aim of this file is to extract yield values from the TECAN and map it to the correct file\n",
    "import numpy as np\n",
    "import csv\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I'm extracting TECAN into a dictionnary (for starters)\n",
    "\n",
    "plate_name = \"PS\"\n",
    "result_name = \"tecan_results\"\n",
    "\n",
    "# plate_name = \"plate_AL_1b\"\n",
    "# result_name = \"plate_AL_1b_raw\"\n",
    "\n",
    "CV = 30\n",
    "folder_result = \"raw_data\"\n",
    "\n",
    "localisation = \"{}/{}.csv\".format(folder_result, result_name)\n",
    "data_source = \"{}/{}_concentrations_reconstituted.csv\".format(folder_result, plate_name)\n",
    "export_place = \"{}/{}_yield_and_std.csv\".format(folder_result, plate_name)\n",
    "all_together_place = \"{}/{}_everything.csv\".format(folder_result, plate_name)\n",
    "draw_mean = \"{}/{}_draw_mean.csv\".format(folder_result, plate_name)\n",
    "draw_std =  \"{}/{}_draw_std.csv\".format(folder_result, plate_name)\n",
    "draw_ratio =  \"{}/{}_draw_ratio.csv\".format(folder_result, plate_name)\n",
    "outliers =  \"{}/{}_outliers.csv\".format(folder_result, plate_name)\n",
    "comments_file = \"{}/{}_comments.txt\".format(folder_result, plate_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_current_data = np.genfromtxt(data_source, delimiter=',', skip_header  = 1, dtype = \"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A6\n",
      "A12\n",
      "A18\n",
      "OrderedDict([('nad', '0.099'), ('folinic_acid', '0.034'), ('DNA', '50'), ('coa', '0.026'), ('RBS', '10'), ('peg', '2'), ('nucleo_mix', '0.75'), ('spermidin', '0.3'), ('pga', '15'), ('aa', '0.75'), ('trna', '0.02'), ('mg_gluta', '1.2'), ('hepes', '50'), ('camp', '0.375'), ('K_gluta', '20'), ('promoter', '10'), ('name', 'P3')])\n"
     ]
    }
   ],
   "source": [
    "wells_information = {}\n",
    "\n",
    "with open(data_source) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        if row[\"name\"] == \"\":\n",
    "            pass\n",
    "        if row[\"name\"] == \"P3\":\n",
    "            print(row)\n",
    "            wells_information[row[\"name\"]] = row\n",
    "        else:\n",
    "            wells_information[row[\"name\"]] = row\n",
    "            if row[\"DNA\"] == \"0\":\n",
    "                print(row[\"name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def present_in_array(new_sample, array):\n",
    "    present = False\n",
    "    new_sample = np.reshape(np.array(new_sample), (1,16))\n",
    "    for i in range(array.shape[0]):\n",
    "        if np.array_equiv(array[i,:],new_sample):\n",
    "            present = True\n",
    "            break\n",
    "    \n",
    "            \n",
    "    return(present, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â Extracting control and plate info separately information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DNA row is 3\n",
      "Empty DNA row (from row) is 3\n",
      "Reference row (from row) is 4\n",
      "C9 is already present and it a duplciate of well C5\n",
      "G3 is 36\n",
      "M18 is 85\n",
      "P3 is 0\n",
      "P3 is 0\n"
     ]
    }
   ],
   "source": [
    "control_array = None\n",
    "plate_array = None\n",
    "control_max_array = None\n",
    "\n",
    "for well, row in wells_information.items():\n",
    "    this_sample_conc = [row[\"nad\"],\n",
    "                        row[\"folinic_acid\"], \n",
    "                        row[\"DNA\"], \n",
    "                        row[\"coa\"], \n",
    "                        row[\"RBS\"], \n",
    "                        row[\"peg\"], \n",
    "                        row[\"nucleo_mix\"],\n",
    "                        row[\"spermidin\"],\n",
    "                        row[\"pga\"],\n",
    "                        row[\"aa\"],\n",
    "                        row[\"trna\"],\n",
    "                        row[\"mg_gluta\"],\n",
    "                        row[\"hepes\"],\n",
    "                        row[\"camp\"],\n",
    "                        row[\"K_gluta\"],\n",
    "                        row[\"promoter\"]\n",
    "                         ]\n",
    "    if well.startswith(\"A\"):        \n",
    "        if control_array is None:\n",
    "            this_sample_conc.extend([well, '', ''])\n",
    "            this_sample_conc = np.reshape(this_sample_conc, (1, 19))\n",
    "            control_array = this_sample_conc \n",
    "        else:\n",
    "            # already present in the array. \n",
    "            # Either file up a new line or...\n",
    "            present, i = present_in_array(this_sample_conc, control_array[:, 0:16])\n",
    "    #         present, i = present_in_array(this_sample_conc[:, 0:16], array_with_wells[:, 0:16])\n",
    "            if not present:    \n",
    "    #             if well == 'M21':\n",
    "    #                 print(i)\n",
    "                if well == 'A6':\n",
    "                    print(\"Empty DNA row is {}\".format(i))\n",
    "                if float(row[\"DNA\"]) == 0:\n",
    "                    print(\"Empty DNA row (from row) is {}\".format(i))\n",
    "                if well == 'M6':\n",
    "                    print(\"Reference row is {}\".format(i))\n",
    "                if float(row[\"K_gluta\"]) == 40 and float(row[\"DNA\"]) != 0:\n",
    "                    print(\"Reference row (from row) is {}\".format(i))\n",
    "                this_sample_conc.extend([well, '', ''])\n",
    "                this_sample_conc = np.reshape(this_sample_conc, (1, 19))\n",
    "                control_array = np.concatenate((control_array, this_sample_conc), axis = 0)\n",
    "            else:\n",
    "                if control_array[i,17] == '':\n",
    "                    control_array[i,17] = well\n",
    "                elif control_array[i,18] == '':\n",
    "                    control_array[i,18] = well\n",
    "                else:\n",
    "                    # print(\"{}, {}, {}\".format(well, row, array_with_wells[i,:]))\n",
    "                    print(row[\"name\"])\n",
    "                    print(\"this makes sense, it's the max\")\n",
    "    elif well.startswith(\"P\"): \n",
    "        if control_max_array is None:\n",
    "            this_sample_conc.extend([well, '', ''])\n",
    "            this_sample_conc = np.reshape(this_sample_conc, (1, 19))\n",
    "            control_max_array = this_sample_conc \n",
    "        else:\n",
    "            # already present in the array. \n",
    "            # Either file up a new line or...\n",
    "            present, i = present_in_array(this_sample_conc, control_max_array[:, 0:16])\n",
    "    #         present, i = present_in_array(this_sample_conc[:, 0:16], array_with_wells[:, 0:16])\n",
    "            if well == 'P3':\n",
    "                print(\"P3 is {}\".format(i))\n",
    "            if not present: \n",
    "                this_sample_conc.extend([well, '', '']) \n",
    "                if well == 'P3':\n",
    "                    print(\"P3 is {}\".format(i))\n",
    "                this_sample_conc = np.reshape(this_sample_conc, (1, 19))\n",
    "                control_max_array = np.concatenate((control_max_array, this_sample_conc), axis = 0)\n",
    "            else:\n",
    "                if control_max_array[i,17] == '':\n",
    "                    control_max_array[i,17] = well\n",
    "                elif control_max_array[i,18] == '':\n",
    "                    control_max_array[i,18] = well\n",
    "                else:\n",
    "                    # print(\"{}, {}, {}\".format(well, row, array_with_wells[i,:]))\n",
    "                    print(row[\"name\"])\n",
    "                    print(\"this makes sense, it's the max\")\n",
    "    else:\n",
    "        if plate_array is None:\n",
    "            this_sample_conc.extend([well, '', ''])\n",
    "            this_sample_conc = np.reshape(this_sample_conc, (1, 19))\n",
    "            plate_array = this_sample_conc\n",
    "        else:\n",
    "            # already present in the array. \n",
    "            # Either file up a new line or...\n",
    "            present, i = present_in_array(this_sample_conc, plate_array[:, 0:16])\n",
    "    #         present, i = present_in_array(this_sample_conc[:, 0:16], array_with_wells[:, 0:16])\n",
    "            if not present:    \n",
    "                if well == 'G3':\n",
    "                    print(\"G3 is {}\".format(i))\n",
    "                if well == 'M6':\n",
    "                    print(\"M6 is {}\".format(i))\n",
    "                if well == 'M18':\n",
    "                    print(\"M18 is {}\".format(i))\n",
    "#                 if well == 'C8':\n",
    "#                     print(i)\n",
    "                this_sample_conc.extend([well, '', ''])\n",
    "                this_sample_conc = np.reshape(this_sample_conc, (1, 19))\n",
    "                plate_array = np.concatenate((plate_array, this_sample_conc), axis = 0)\n",
    "            else:\n",
    "                if plate_array[i,17] == '':\n",
    "                    plate_array[i,17] = well\n",
    "                elif plate_array[i,18] == '':\n",
    "                    plate_array[i,18] = well\n",
    "                else:\n",
    "                    print(\"{} is already present and it a duplciate of well {}\".format(row[\"name\"], plate_array[i,16]))\n",
    "                    this_sample_conc.extend([well, '', ''])\n",
    "                    this_sample_conc = np.reshape(this_sample_conc, (1, 19))\n",
    "                    plate_array = np.concatenate((this_sample_conc, plate_array), axis = 0)\n",
    "                    #Â print(row)\n",
    "                    # print(\"this makes sense, it's the max\")\n",
    "# print(plate_array.shape)\n",
    "# print(plate_array[1:15, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0.033' '0.0068' '50' '0.026' '10' '2' '0.15' '0.1' '3' '0.15' '0.02'\n",
      "  '0.4' '50' '0.075' '4' '10' 'A2' 'A8' 'A14']\n",
      " ['0.165' '0.0068' '50' '0.026' '10' '2' '0.15' '0.1' '9' '0.15' '0.02'\n",
      "  '0.4' '50' '0.375' '12' '10' 'A3' 'A9' 'A15']\n",
      " ['0.099' '0.0204' '50' '0.078' '10' '2' '0.15' '0.5' '3' '0.45' '0.1'\n",
      "  '1.2' '50' '0.225' '4' '10' 'A4' 'A10' 'A16']\n",
      " ['0.033' '0.0204' '50' '0.078' '10' '2' '0.15' '0.5' '9' '0.45' '0.06'\n",
      "  '2' '50' '0.225' '12' '10' 'A5' 'A11' 'A17']\n",
      " ['0.33' '0.068' '0' '0.26' '10' '2' '1.5' '1' '30' '1.5' '0.2' '4' '50'\n",
      "  '0.75' '40' '10' 'A6' 'A12' 'A18']\n",
      " ['0.33' '0.068' '50' '0.26' '10' '2' '1.5' '1' '30' '1.5' '0.2' '4' '50'\n",
      "  '0.75' '40' '10' 'A7' 'A13' 'A19']]\n",
      "['0.33' '0.068' '0' '0.26' '10' '2' '1.5' '1' '30' '1.5' '0.2' '4' '50'\n",
      " '0.75' '40' '10' 'A6' 'A12' 'A18']\n",
      "['0.33' '0.068' '50' '0.26' '10' '2' '1.5' '1' '30' '1.5' '0.2' '4' '50'\n",
      " '0.75' '40' '10' 'A7' 'A13' 'A19']\n",
      "['0.33' '0.068' '0' '0.26' '10' '2' '1.5' '1' '30' '1.5' '0.2' '4' '50'\n",
      " '0.75' '40' '10' 'A6' 'A12' 'A18']\n",
      "['0.33' '0.068' '50' '0.26' '10' '2' '1.5' '1' '30' '1.5' '0.2' '4' '50'\n",
      " '0.75' '40' '10' 'A7' 'A13' 'A19']\n"
     ]
    }
   ],
   "source": [
    "print(control_array)\n",
    "if control_array is None:\n",
    "    whole_array = plate_array\n",
    "else:\n",
    "    print(control_array[4,])\n",
    "    print(control_array[5,])\n",
    "    try:\n",
    "        whole_array = np.concatenate((control_array, plate_array, control_max_array), axis = 0)\n",
    "    except ValueError:\n",
    "        whole_array = np.concatenate((control_array, control_max_array), axis = 0)\n",
    "    print(whole_array[4,])\n",
    "    print(whole_array[5,])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115, 19)\n"
     ]
    }
   ],
   "source": [
    "print(whole_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â Replacing named wells with their values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_yield_dictionnary = {}\n",
    "\n",
    "with open(localisation) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        name_yield_dictionnary[row[\"name\"]] = row[\"Time_5\"]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A2': '9114', 'A3': '5870', 'A4': '6080', 'A5': '3441', 'A6': '2287', 'A7': '4138', 'A8': '9435', 'A9': '5654', 'A10': '5762', 'A11': '3581', 'A12': '2325', 'A13': '3229', 'A14': '9280', 'A15': '5283', 'A16': '5615', 'A17': '3283', 'A18': '2222', 'A19': '2695', 'A20': '138', 'A21': '155', 'A22': '140', 'A23': '144', 'A24': '141', 'B2': '13955', 'B3': '13881', 'B4': '13821', 'B5': '11109', 'B6': '11081', 'B7': '11553', 'B8': '14896', 'B9': '14384', 'B10': '13562', 'B11': '7660', 'B12': '7593', 'B13': '7621', 'B14': '16927', 'B15': '17047', 'B16': '16498', 'B17': '15417', 'B18': '14937', 'B19': '15007', 'B20': '17851', 'B21': '17810', 'B22': '18021', 'B23': '14796', 'B24': '147', 'C2': '14629', 'C3': '14597', 'C4': '18189', 'C5': '18157', 'C6': '18967', 'C7': '17308', 'C8': '18452', 'C9': '17918', 'C10': '16985', 'C11': '18777', 'C12': '17178', 'C13': '8472', 'C14': '8517', 'C15': '8385', 'C16': '16559', 'C17': '15742', 'C18': '16058', 'C19': '15055', 'C20': '16572', 'C21': '14894', 'C22': '16787', 'C23': '16788', 'C24': '144', 'D2': '19649', 'D3': '18110', 'D4': '17558', 'D5': '17205', 'D6': '14724', 'D7': '14541', 'D8': '14416', 'D9': '18437', 'D10': '17384', 'D11': '17229', 'D12': '17937', 'D13': '17637', 'D14': '17898', 'D15': '18332', 'D16': '17412', 'D17': '16917', 'D18': '14927', 'D19': '16217', 'D20': '15217', 'D21': '16259', 'D22': '14777', 'D23': '15703', 'D24': '148', 'E2': '16492', 'E3': '15683', 'E4': '15323', 'E5': '28711', 'E6': '28963', 'E7': '29558', 'E8': '31820', 'E9': '32422', 'E10': '32393', 'E11': '32610', 'E12': '33392', 'E13': '32355', 'E14': '28605', 'E15': '29168', 'E16': '33269', 'E17': '29243', 'E18': '28881', 'E19': '29483', 'E20': '28834', 'E21': '27607', 'E22': '29872', 'E23': '28221', 'E24': '144', 'F2': '29963', 'F3': '29984', 'F4': '32932', 'F5': '32911', 'F6': '32420', 'F7': '28248', 'F8': '28891', 'F9': '29107', 'F10': '11540', 'F11': '21112', 'F12': '12351', 'F13': '21613', 'F14': '12679', 'F15': '21151', 'F16': '4640', 'F17': '4561', 'F18': '4572', 'F19': '13200', 'F20': '12793', 'F21': '12411', 'F22': '18192', 'F23': '17612', 'F24': '143', 'G2': '16275', 'G3': '19776', 'G4': '20017', 'G5': '19169', 'G6': '23618', 'G7': '14699', 'G8': '23927', 'G9': '14731', 'G10': '22518', 'G11': '14483', 'G12': '17848', 'G13': '18809', 'G14': '17761', 'G15': '21932', 'G16': '19939', 'G17': '21040', 'G18': '22312', 'G19': '20834', 'G20': '22193', 'G21': '3970', 'G22': '4042', 'G23': '3544', 'G24': '139', 'H2': '23452', 'H3': '24521', 'H4': '23754', 'H5': '22917', 'H6': '23395', 'H7': '23558', 'H8': '22525', 'H9': '23270', 'H10': '23938', 'H11': '22997', 'H12': '22896', 'H13': '22498', 'H14': '23689', 'H15': '23263', 'H16': '23064', 'H17': '5240', 'H18': '4967', 'H19': '5209', 'H20': '20310', 'H21': '20051', 'H22': '20447', 'H23': '19195', 'H24': '140', 'I2': '21287', 'I3': '21226', 'I4': '23732', 'I5': '22844', 'I6': '21257', 'I7': '21216', 'I8': '24202', 'I9': '23467', 'I10': '4880', 'I11': '4813', 'I12': '4674', 'I13': '20299', 'I14': '18794', 'I15': '19571', 'I16': '37288', 'I17': '37112', 'I18': '38015', 'I19': '33795', 'I20': '36220', 'I21': '33258', 'I22': '34412', 'I23': '32217', 'I24': '142', 'J2': '36490', 'J3': '10240', 'J4': '10242', 'J5': '9468', 'J6': '25682', 'J7': '26338', 'J8': '27325', 'J9': '4015', 'J10': '39456', 'J11': '4505', 'J12': '4974', 'J13': '38690', 'J14': '3849', 'J15': '4193', 'J16': '38593', 'J17': '3622', 'J18': '11279', 'J19': '13214', 'J20': '12670', 'J21': '12524', 'J22': '12741', 'J23': '12180', 'J24': '135', 'K2': '5026', 'K3': '39667', 'K4': '5471', 'K5': '38707', 'K6': '5039', 'K7': '39132', 'K8': '17467', 'K9': '17571', 'K10': '16365', 'K11': '37814', 'K12': '36149', 'K13': '36491', 'K14': '29810', 'K15': '31864', 'K16': '30727', 'K17': '43262', 'K18': '43264', 'K19': '43164', 'K20': '39208', 'K21': '38824', 'K22': '38524', 'K23': '37719', 'K24': '141', 'L2': '37737', 'L3': '38450', 'L4': '36464', 'L5': '40545', 'L6': '39022', 'L7': '41653', 'L8': '41664', 'L9': '39745', 'L10': '40755', 'L11': '37119', 'L12': '40106', 'L13': '39032', 'L14': '40398', 'L15': '40918', 'L16': '35854', 'L17': '39732', 'L18': '36066', 'L19': '32650', 'L20': '33361', 'L21': '31905', 'L22': '34789', 'L23': '33550', 'L24': '144', 'M2': '34460', 'M3': '40534', 'M4': '40162', 'M5': '41031', 'M6': '39557', 'M7': '40572', 'M8': '40913', 'M9': '42053', 'M10': '37776', 'M11': '41194', 'M12': '41771', 'M13': '41652', 'M14': '42779', 'M15': '38587', 'M16': '36895', 'M17': '36333', 'M18': '34642', 'M19': '33380', 'M20': '34589', 'M21': '41191', 'M22': '39748', 'M23': '39761', 'M24': '137', 'N2': '31913', 'N3': '32886', 'N4': '33820', 'N5': '41541', 'N6': '40331', 'N7': '42120', 'N8': '38248', 'N9': '39467', 'N10': '42154', 'N11': '40628', 'N12': '41656', 'N13': '38591', 'N14': '39345', 'N15': '42023', 'N16': '38367', 'N17': '40443', 'N18': '40684', 'N19': '36260', 'N20': '39781', 'N21': '37917', 'N22': '39460', 'N23': '39109', 'N24': '142', 'O2': '39959', 'O3': '40292', 'O4': '39366', 'O5': '38687', 'O6': '38278', 'O7': '34861', 'O8': '36748', 'O9': '33926', 'O10': '39646', 'O11': '33013', 'O12': '41038', 'O13': '39446', 'O14': '41793', 'O15': '40043', 'O16': '5276', 'O17': '5316', 'O18': '5223', 'O19': '1870', 'O20': '1971', 'O21': '1914', 'O22': '258', 'O23': '538', 'O24': '137', 'P2': '15449', 'P3': '21822', 'P4': '12598', 'P5': '21355', 'P6': '43693', 'P7': '41290', 'P8': '39357', 'P9': '16778', 'P10': '19555', 'P11': '11099', 'P12': '15024', 'P13': '45168', 'P14': '37721', 'P15': '38200', 'P16': '15758', 'P17': '20269', 'P18': '10872', 'P19': '18927', 'P20': '40668', 'P21': '39981', 'P22': '36931', 'P23': '144', 'P24': '152'}\n"
     ]
    }
   ],
   "source": [
    "print(name_yield_dictionnary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wells_name_array = np.copy(whole_array[:,16:19])\n",
    "#Â print(wells_name_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(whole_array.shape[0]):\n",
    "    for j in range(16,19):\n",
    "        try:\n",
    "            whole_array[i,j] = name_yield_dictionnary[whole_array[i,j]]\n",
    "        except KeyError:\n",
    "            whole_array[i,j] = -10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115, 19)\n",
      "[[3.3000e-02 6.8000e-03 5.0000e+01 ... 9.1140e+03 9.4350e+03 9.2800e+03]\n",
      " [1.6500e-01 6.8000e-03 5.0000e+01 ... 5.8700e+03 5.6540e+03 5.2830e+03]\n",
      " [9.9000e-02 2.0400e-02 5.0000e+01 ... 6.0800e+03 5.7620e+03 5.6150e+03]\n",
      " ...\n",
      " [1.6500e-01 6.8000e-02 5.0000e+01 ... 4.3693e+04 4.5168e+04 4.0668e+04]\n",
      " [9.9000e-02 3.4000e-02 5.0000e+01 ... 4.1290e+04 3.7721e+04 3.9981e+04]\n",
      " [3.3000e-02 2.0400e-02 5.0000e+01 ... 3.9357e+04 3.8200e+04 3.6931e+04]]\n"
     ]
    }
   ],
   "source": [
    "whole_array = whole_array.astype(np.float32)\n",
    "print(whole_array.shape)\n",
    "print(whole_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier_cv(row, cv):\n",
    "    x = row[16:19]\n",
    "    main_row = row[0:16]\n",
    "    mean = np.mean(x)\n",
    "    sd = np.std(x)\n",
    "    ratio = sd/mean * 100\n",
    "    if ratio > cv:\n",
    "        min_index = np.argmin(x)\n",
    "        max_index = np.argmax(x)\n",
    "        other_point_arg = 3 - min_index - max_index\n",
    "        if (x[other_point_arg] - x[min_index]) > (x[max_index] - x[other_point_arg]):\n",
    "            # Distance between medium and low is above distance between max and medium: discard lowest\n",
    "            new_x = np.concatenate((x[[other_point_arg, max_index]], np.array([-1])), axis = 0)\n",
    "        else:\n",
    "            new_x = np.concatenate((x[[min_index, other_point_arg]], np.array([-1])), axis = 0)\n",
    "        return(True, np.concatenate((main_row, new_x), axis = 0), row)\n",
    "    else:\n",
    "        return(False, row, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_array = None\n",
    "cleaned_array = None\n",
    "\n",
    "for row in whole_array:\n",
    "   # print(row.shape)\n",
    "    outlier, row, outlier_row = remove_outlier_cv(row, cv = CV)\n",
    "    if outlier:\n",
    "        print(row[16:19])\n",
    "        print(outlier_row[16:19])\n",
    "        if outliers_array is None:\n",
    "            outliers_array = np.reshape(outlier_row, (1, 19)) \n",
    "        else:\n",
    "            outliers_array = np.concatenate((outliers_array, np.reshape(outlier_row, (1, 19))), axis = 0)\n",
    "    if cleaned_array is None:\n",
    "        cleaned_array = np.reshape(row, (1, 19)) \n",
    "    else:\n",
    "        cleaned_array = np.concatenate((cleaned_array, np.reshape(row, (1, 19))), axis = 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(outliers_array)\n",
    "if outliers_array is None:\n",
    "    number_outliers = 0\n",
    "else:\n",
    "    print(outliers_array.shape)\n",
    "    number_outliers = outliers_array.shape[0]\n",
    "number_total = whole_array.shape[0]\n",
    "number_bis = cleaned_array.shape[0]\n",
    "assert number_bis == number_total\n",
    "percentage = number_outliers/number_total * 100\n",
    "text = \"There are {} outliers out of {} ({}%) for CV of {}\".format(number_outliers, number_total, round(percentage, 2), CV)\n",
    "with open(comments_file, \"w\") as file_handle:\n",
    "    file_handle.write(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(outliers_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_as_dict = []\n",
    "fieldnames = [\"nad\", \"folinic_acid\", \"DNA\", \"coa\", \"RBS\", \"peg\", \"nucleo_mix\", \n",
    "              \"spermidin\", \"pga\", \"aa\", \"trna\", \"mg_gluta\", \"hepes\", \"camp\", \"K_gluta\", \"promoter\", \n",
    "              \"value_1\", \"value_2\", \"value_3\", \"plaque_name\"]\n",
    "\n",
    "if not outliers_array is None:\n",
    "    for row in outliers_array:\n",
    "        new_dict = {}\n",
    "        new_dict[\"nad\"] = round(float(row[0]), 5)\n",
    "        new_dict[\"folinic_acid\"] = round(float(row[1]), 5)\n",
    "        new_dict[\"DNA\"] = round(float(row[2]), 4)\n",
    "        new_dict[\"coa\"] = round(float(row[3]), 5)\n",
    "        new_dict[\"RBS\"] = round(float(row[4]), 4)\n",
    "        new_dict[\"peg\"] = round(float(row[5]), 5)\n",
    "        new_dict[\"nucleo_mix\"] = round(float(row[6]), 5)\n",
    "        new_dict[\"spermidin\"] = round(float(row[7]), 5)\n",
    "        new_dict[\"pga\"] = round(float(row[8]), 5)\n",
    "        new_dict[\"aa\"] = round(float(row[9]), 5)\n",
    "        new_dict[\"trna\"] = round(float(row[10]), 5)\n",
    "        new_dict[\"mg_gluta\"] = round(float(row[11]), 4)\n",
    "        new_dict[\"hepes\"] = round(float(row[12]), 4)\n",
    "        new_dict[\"camp\"] = round(float(row[13]), 4)\n",
    "        new_dict[\"K_gluta\"] = round(float(row[14]), 4)\n",
    "        new_dict[\"promoter\"] = round(float(row[15]), 4)\n",
    "        new_dict[\"value_1\"] = round(float(row[16]), 4)\n",
    "        new_dict[\"value_2\"] = round(float(row[17]), 4)\n",
    "        new_dict[\"value_3\"] = round(float(row[18]), 4)\n",
    "        new_dict[\"plaque_name\"] = plate_name\n",
    "        outliers_as_dict.append(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outliers, \"w\") as csv_handle:\n",
    "    csv_writer = csv.DictWriter(csv_handle, fieldnames, restval='', extrasaction='ignore')\n",
    "    csv_writer.writeheader()\n",
    "    for result in outliers_as_dict:\n",
    "        csv_writer.writerow(result)\n",
    "        # print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115, 19)\n",
      "[2287. 2325. 2222.]\n",
      "[21822. 19555. 20269.]\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_array.shape)\n",
    "\n",
    "if control_array is None:\n",
    "    print(\"controls are different\")\n",
    "    autofluo = whole_array[4,16:19]\n",
    "    autofluo_reference = np.array([5042, 4913, 4741])\n",
    "    max_extract = np.array([24606, 25235, 23426])\n",
    "else:\n",
    "    try: \n",
    "        max_extract = cleaned_array[109,16:19]  # Will be changed to reference extract in later versions of the code\n",
    "    except:\n",
    "        max_extract = cleaned_array[7,16:19]\n",
    "        \n",
    "    autofluo = whole_array[4,16:19]\n",
    "    autofluo_reference = autofluo\n",
    "\n",
    "print(autofluo)\n",
    "print(max_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_yield_mean_sd(x, autofluo, ref_fluo, autofluo_reference = None):\n",
    "    if autofluo_reference is None:\n",
    "        autofluo_reference = autofluo\n",
    "    combinations = []\n",
    "    auto_value = np.mean(autofluo)\n",
    "    auto_value_ref = np.mean(autofluo_reference)\n",
    "    \n",
    "    if ref_fluo[2] == -1:\n",
    "        ref_fluo = ref_fluo[0:2] \n",
    "    ref_value = np.mean(ref_fluo)\n",
    "    ref_value = np.mean(ref_fluo)\n",
    "    if x[2] == -1:\n",
    "        x = x[0:2]  \n",
    "    for value_x in x:\n",
    "        if value_x == np.array([-1]):\n",
    "            pass\n",
    "        else:\n",
    "            normlised_value = (value_x - auto_value)/(ref_value - auto_value_ref)\n",
    "            combinations.append(normlised_value)\n",
    "    yield_mean = np.mean(combinations)\n",
    "    yield_sd = np.std(combinations)\n",
    "    return({\"yield_mean\": yield_mean, \"yield_std\": yield_sd})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "autofluo_from_data = autofluo\n",
    "max_from_data = max_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yield_mean': 1.0, 'yield_std': 0.051798366}\n",
      "{'yield_mean': 0.0, 'yield_std': 0.0023276887}\n"
     ]
    }
   ],
   "source": [
    "# Verifications \n",
    "print(calculate_yield_mean_sd(x = max_from_data, autofluo = autofluo_from_data, \n",
    "                              ref_fluo = max_from_data, autofluo_reference = autofluo_reference))\n",
    "print(calculate_yield_mean_sd(x = autofluo_from_data, autofluo = autofluo_from_data, \n",
    "                              ref_fluo = max_from_data, autofluo_reference = autofluo_reference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_array = cleaned_array[:,0:16]\n",
    "full_array = cleaned_array[:,0:19]\n",
    "mean_yield_list = []\n",
    "std_yield_list = []\n",
    "mean_list = []\n",
    "std_list = []\n",
    "\n",
    "\n",
    "for i in range(cleaned_array.shape[0]):\n",
    "    if cleaned_array[i, 18] == -1:\n",
    "        mean = np.mean(cleaned_array[i, 16:18])\n",
    "        std = np.std(cleaned_array[i, 16:18])\n",
    "    else:\n",
    "        mean = np.mean(cleaned_array[i, 16:19])\n",
    "        std = np.std(cleaned_array[i, 16:19])\n",
    "    dict_results = calculate_yield_mean_sd(cleaned_array[i, 16:19], autofluo_from_data, max_from_data)\n",
    "    yield_mean = dict_results[\"yield_mean\"]\n",
    "    yield_std = dict_results[\"yield_std\"]\n",
    "    mean_yield_list.append(yield_mean)\n",
    "    std_yield_list.append(yield_std)\n",
    "    mean_list.append(mean)\n",
    "    std_list.append(std)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115, 16)\n",
      "(115, 19)\n"
     ]
    }
   ],
   "source": [
    "print(new_array.shape)\n",
    "print(full_array.shape)\n",
    "full_array = np.concatenate((full_array, wells_name_array), axis = 1)\n",
    "#Â print(full_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_array = np.reshape(mean_list, (new_array.shape[0], 1))\n",
    "std_array = np.reshape(std_list, (new_array.shape[0], 1))\n",
    "mean_yield_array = np.reshape(mean_yield_list, (new_array.shape[0], 1))\n",
    "std_yield_array = np.reshape(std_yield_list, (new_array.shape[0], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115, 20)\n",
      "(115, 26)\n"
     ]
    }
   ],
   "source": [
    "array_for_saving = np.concatenate((new_array, mean_array, std_array, mean_yield_array, std_yield_array), axis = 1)\n",
    "print(array_for_saving.shape)\n",
    "array_for_saving_everything = np.concatenate((full_array, mean_array, std_array, mean_yield_array, std_yield_array), axis = 1)\n",
    "print(array_for_saving_everything.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â np.savetxt(export_place, array_for_saving, delimiter=\";\",fmt='%.5f')\n",
    "\n",
    "#Â np.savetxt(all_together_place, array_for_saving_everything, delimiter=\";\",fmt='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is zero\n",
      "{'nad': 0.33, 'folinic_acid': 0.068, 'DNA': 0.0, 'coa': 0.26, 'RBS': 10.0, 'peg': 2.0, 'nucleo_mix': 1.5, 'spermidin': 1.0, 'pga': 30.0, 'aa': 1.5, 'trna': 0.2, 'mg_gluta': 4.0, 'hepes': 50.0, 'camp': 0.75, 'K_gluta': 40.0, 'promoter': 10.0, 'value_1': 2287.0, 'value_2': 2325.0, 'value_3': 2222.0, 'well_1': 'A6', 'well_2': 'A12', 'well_3': 'A18', 'mean': 2278.0, 'std': 42.5, 'yield': 0.0, 'yield_std': 0.0023, 'plaque_name': 'PS'}\n"
     ]
    }
   ],
   "source": [
    "list_of_dict_everything = []\n",
    "list_of_dict_ML = []\n",
    "fieldnames = [\"nad\", \"folinic_acid\", \"DNA\", \"coa\", \"RBS\", \"peg\", \"nucleo_mix\", \n",
    "              \"spermidin\", \"pga\", \"aa\", \"trna\", \"mg_gluta\", \"hepes\", \"camp\", \"K_gluta\", \"promoter\", \n",
    "              \"value_1\", \"value_2\", \"value_3\", \"well_1\", \"well_2\", \"well_3\", \"mean\", \"std\", \"yield\", \"yield_std\",\n",
    "             \"plaque_name\"]\n",
    "\n",
    "for row in array_for_saving_everything:\n",
    "    new_dict = {}\n",
    "    new_dict[\"nad\"] = round(float(row[0]), 5)\n",
    "    new_dict[\"folinic_acid\"] = round(float(row[1]), 5)\n",
    "    new_dict[\"DNA\"] = round(float(row[2]), 4)\n",
    "    new_dict[\"coa\"] = round(float(row[3]), 5)\n",
    "    new_dict[\"RBS\"] = round(float(row[4]), 4)\n",
    "    new_dict[\"peg\"] = round(float(row[5]), 5)\n",
    "    new_dict[\"nucleo_mix\"] = round(float(row[6]), 5)\n",
    "    new_dict[\"spermidin\"] = round(float(row[7]), 5)\n",
    "    new_dict[\"pga\"] = round(float(row[8]), 5)\n",
    "    new_dict[\"aa\"] = round(float(row[9]), 5)\n",
    "    new_dict[\"trna\"] = round(float(row[10]), 5)\n",
    "    new_dict[\"mg_gluta\"] = round(float(row[11]), 4)\n",
    "    new_dict[\"hepes\"] = round(float(row[12]), 4)\n",
    "    new_dict[\"camp\"] = round(float(row[13]), 4)\n",
    "    new_dict[\"K_gluta\"] = round(float(row[14]), 4)\n",
    "    new_dict[\"promoter\"] = round(float(row[15]), 4)\n",
    "    new_dict[\"value_1\"] = round(float(row[16]), 4)\n",
    "    new_dict[\"value_2\"] = round(float(row[17]), 4)\n",
    "    new_dict[\"value_3\"] = round(float(row[18]), 4)\n",
    "    new_dict[\"well_1\"] = row[19]\n",
    "    new_dict[\"well_2\"] = row[20]\n",
    "    new_dict[\"well_3\"] = row[21]\n",
    "    new_dict[\"mean\"] = round(float(row[22]), 1)\n",
    "    new_dict[\"std\"] = round(float(row[23]), 1)\n",
    "    new_dict[\"yield\"] = round(float(row[24]), 4)\n",
    "    new_dict[\"yield_std\"] = round(float(row[25]), 4)\n",
    "    new_dict[\"plaque_name\"] = plate_name\n",
    "    if round(float(row[2]), 4) == 0:\n",
    "        print(\"is zero\")\n",
    "        print(new_dict)\n",
    "    else:\n",
    "        list_of_dict_ML.append(new_dict)\n",
    "    list_of_dict_everything.append(new_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(all_together_place, \"w\") as csv_handle:\n",
    "    csv_writer = csv.DictWriter(csv_handle, fieldnames, restval='', extrasaction='ignore')\n",
    "    csv_writer.writeheader()\n",
    "    for result in list_of_dict_everything:\n",
    "        csv_writer.writerow(result)\n",
    "        # print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldnames_for_ml = [\"nad\", \"folinic_acid\", \"coa\", \"nucleo_mix\", \n",
    "                    \"spermidin\", \"pga\", \"aa\", \"trna\", \"mg_gluta\", \"camp\", \"K_gluta\", \n",
    "                     \"yield\", \"yield_std\"]\n",
    "with open(export_place, \"w\") as csv_handle:\n",
    "    csv_writer = csv.DictWriter(csv_handle, fieldnames_for_ml, restval='', extrasaction='ignore')\n",
    "    csv_writer.writeheader()\n",
    "    for result in list_of_dict_ML:\n",
    "        csv_writer.writerow(result)\n",
    "        # print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['row', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23']\n"
     ]
    }
   ],
   "source": [
    "# Draw the plaque - take from the instruction AA script for more ideas.\n",
    "fieldnames_plate = ['row']\n",
    "for i in range(2,24):\n",
    "    fieldnames_plate.append(str(i))\n",
    "print(fieldnames_plate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_info, std_info, ratio_info = {}, {}, {}\n",
    "# \"well_1\", \"well_2\", \"well_3\"\n",
    "for element in list_of_dict_everything:\n",
    "    mean_info[element[\"well_1\"]] = element[\"mean\"]\n",
    "    std_info[element[\"well_1\"]] = element[\"std\"]\n",
    "    ratio_info[element[\"well_1\"]] = float(element[\"std\"])/float(element[\"mean\"]) * 100\n",
    "    mean_info[element[\"well_2\"]] = element[\"mean\"]\n",
    "    std_info[element[\"well_2\"]] = element[\"std\"]\n",
    "    ratio_info[element[\"well_2\"]] = float(element[\"std\"])/float(element[\"mean\"]) * 100\n",
    "    mean_info[element[\"well_3\"]] = element[\"mean\"]\n",
    "    std_info[element[\"well_3\"]] = element[\"std\"]\n",
    "    ratio_info[element[\"well_3\"]] = float(element[\"std\"])/float(element[\"mean\"]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(draw_mean, \"w\") as mean_drawing_file:\n",
    "    writer = csv.DictWriter(mean_drawing_file, fieldnames=fieldnames_plate, restval='0')\n",
    "    writer.writeheader()\n",
    "    current_row = 'A'\n",
    "    row = {}\n",
    "    row[\"row\"] = current_row\n",
    "    for element in sorted(mean_info.keys()):\n",
    "#         print(row)\n",
    "#         print(element)\n",
    "        if element.startswith(current_row):\n",
    "            row[element[1:]] = mean_info[element]\n",
    "        else:\n",
    "            writer.writerow(row)\n",
    "            current_row = element[0]\n",
    "            row = {\"row\": current_row}\n",
    "            row[element[1:]] = mean_info[element]\n",
    "    writer.writerow(row)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(draw_std, \"w\") as std_drawing_file:\n",
    "    writer = csv.DictWriter(std_drawing_file, fieldnames=fieldnames_plate, restval='0')\n",
    "    writer.writeheader()\n",
    "    current_row = 'A'\n",
    "    row = {}\n",
    "    row[\"row\"] = current_row\n",
    "    for element in sorted(std_info.keys()):\n",
    "#         print(row)\n",
    "#         print(element)\n",
    "        if element.startswith(current_row):\n",
    "            row[element[1:]] = std_info[element]\n",
    "        else:\n",
    "            writer.writerow(row)\n",
    "            current_row = element[0]\n",
    "            row = {\"row\": current_row}\n",
    "            row[element[1:]] = std_info[element]\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(draw_ratio, \"w\") as ratio_drawing_file:\n",
    "    writer = csv.DictWriter(ratio_drawing_file, fieldnames=fieldnames_plate, restval='0')\n",
    "    writer.writeheader()\n",
    "    current_row = 'A'\n",
    "    row = {}\n",
    "    row[\"row\"] = current_row\n",
    "    for element in sorted(ratio_info.keys()):\n",
    "#         print(row)\n",
    "#         print(element)\n",
    "        if element.startswith(current_row):\n",
    "            row[element[1:]] = ratio_info[element]\n",
    "        else:\n",
    "            writer.writerow(row)\n",
    "            current_row = element[0]\n",
    "            row = {\"row\": current_row}\n",
    "            row[element[1:]] = ratio_info[element]\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
